# AI 题库生成 Pipeline —— 技术文档

> 版本：v1.0 | 更新日期：2026-02-22
> 适用范围：`rag_pipeline/` 目录下所有模块

---

## 目录

1. [系统概述](#1-系统概述)
2. [技术栈与依赖](#2-技术栈与依赖)
3. [整体架构](#3-整体架构)
4. [数据库 Schema](#4-数据库-schema)
5. [模块详解](#5-模块详解)
   - 5.1 [文档解析 parser.py](#51-文档解析-parserpy)
   - 5.2 [数据库层 db.py](#52-数据库层-dbpy)
   - 5.3 [知识图谱提取 kg_extractor.py](#53-知识图谱提取-kg_extractorpy)
   - 5.4 [Prompt 工程 prompts.py](#54-prompt-工程-promptspy)
   - 5.5 [题目生成 question_generator.py](#55-题目生成-question_generatorpy)
   - 5.6 [断点续传机制](#56-断点续传机制)
   - 5.7 [交互菜单 main.py](#57-交互菜单-mainpy)
   - 5.8 [API Key 配置 _setup_key.py](#58-api-key-配置-_setup_keypy)
6. [知识图谱的作用与局限](#6-知识图谱的作用与局限)
7. [Token 用量与成本估算](#7-token-用量与成本估算)
8. [配置参数说明](#8-配置参数说明)
9. [通用化前端版本设计方案](#9-通用化前端版本设计方案)

---

## 1. 系统概述

本系统以 OCR 转换后的 Markdown 教材文本为输入，通过**两阶段 LLM 调用**自动生成结构化题库：

```
第一阶段：知识图谱提取
  教材文本 ──[DeepSeek]──▶ 结构化知识点 + 概念关系 ──▶ SQLite

第二阶段：知识图谱驱动出题
  教材文本 + 知识图谱 ──[DeepSeek]──▶ 题目（系统导入格式）──▶ .txt 文件
```

**设计目标：**
- 覆盖率优先：确保每章重难点都有对应题目，而非随机采样
- 题型精准：通过关系图谱把"对比关系"映射到比较题、"因果关系"映射到论述题
- 可中断：断点续传，不浪费已消耗的 API token
- 零入侵：独立于现有 Flask 系统，输出格式与现有导入格式完全兼容

---

## 2. 技术栈与依赖

| 组件 | 选型 | 说明 |
|------|------|------|
| LLM API | DeepSeek-V3 (`deepseek-chat`) | 兼容 OpenAI SDK，64K 上下文，性价比高 |
| API 客户端 | `openai>=1.0` | 直接复用 OpenAI Python SDK |
| 向量数据库 | — | 本版本不使用，全文本直接入 prompt |
| 知识图谱存储 | SQLite（`kg.db`） | 零部署成本，关系查询够用 |
| 环境变量 | `python-dotenv` | 从 `.env` 读取 API Key |
| GUI 对话框 | `tkinter`（标准库） | API Key 输入界面，无需额外安装 |
| 启动脚本 | Windows `.bat` | 自动激活 venv、安装依赖、启动菜单 |

**运行环境：**
- Python 3.10+（使用了 `str | None` 类型注解语法）
- 虚拟环境：项目根目录 `venv/`
- 操作系统：Windows（脚本），核心 Python 代码跨平台

---

## 3. 整体架构

```
D:\code\试卷\试卷生成\
├── .env                          # API Key（不跟踪）
├── 一键启动_AI出题.bat            # 入口：激活 venv → 安装依赖 → GUI → 菜单
│
└── rag_pipeline/
    ├── __main__.py               # python -m rag_pipeline 入口
    ├── config.py                 # 路径、模型、题量全局配置
    ├── parser.py                 # [Stage 0] MD 文档解析
    ├── db.py                     # [Storage]  SQLite 知识图谱 CRUD
    ├── prompts.py                # [Prompt]   两阶段 Prompt 模板
    ├── kg_extractor.py           # [Stage 1]  DeepSeek 提取知识图谱
    ├── question_generator.py     # [Stage 2]  DeepSeek 生成题目
    ├── main.py                   # [UI]       交互菜单
    ├── _setup_key.py             # [Setup]    tkinter API Key 配置
    ├── requirements.txt          # python-dotenv, openai
    │
    ├── kg.db                     # 知识图谱数据库（运行时生成，不跟踪）
    ├── progress.json             # 断点进度文件（运行时生成，不跟踪）
    └── output/                   # 生成的题目 txt 文件（不跟踪）
        ├── chapter_01_第一章_农业经营制度.txt
        ├── ...
        └── all_questions.txt     # 合并文件，可直接导入题库系统
```

**数据流图：**

```
农业经济学1.pdf_by_PaddleOCR.md
          │
          ▼
    ┌─────────────┐
    │  parser.py  │  正则切分章节，提取学习目标
    └──────┬──────┘
           │ list[chapter_dict]
           ▼
    ┌──────────────────┐     ┌───────────────┐
    │  kg_extractor.py │────▶│   DeepSeek    │
    │  （第一次调用）   │◀────│  (JSON 输出)  │
    └──────┬───────────┘     └───────────────┘
           │ kg_data (concepts + relations)
           ▼
    ┌─────────────┐
    │    db.py    │  写入 SQLite kg.db
    └──────┬──────┘
           │
           ▼
    ┌───────────────────────┐     ┌───────────────┐
    │ question_generator.py │────▶│   DeepSeek    │
    │  （第二次调用）        │◀────│  (题目文本)   │
    └──────────┬────────────┘     └───────────────┘
               │
               ▼
    output/chapter_XX_*.txt  ──合并──▶  all_questions.txt
                                              │
                                              ▼
                                    现有题库系统「导入题库」
```

---

## 4. 数据库 Schema

使用单文件 SQLite（`kg.db`），三张表构成有向知识图谱：

```sql
-- 章节表：存储章节元数据和截断后的文本
CREATE TABLE chapters (
    id             INTEGER PRIMARY KEY,   -- 0=导论, 1=第一章, ...
    number         TEXT NOT NULL,         -- '导论' / '第一章'
    name           TEXT NOT NULL,         -- '农业经营制度'
    content        TEXT NOT NULL,         -- 截断后文本（≤30000字）
    learning_goals TEXT DEFAULT ''        -- 从学习目标段落提取
);

-- 概念节点表
CREATE TABLE concepts (
    id                  INTEGER PRIMARY KEY AUTOINCREMENT,
    chapter_id          INTEGER NOT NULL,
    name                TEXT NOT NULL,
    description         TEXT DEFAULT '',     -- 一句话定义（≤20字）
    is_key_point        INTEGER DEFAULT 0,   -- 1=必考重点
    is_difficult_point  INTEGER DEFAULT 0,   -- 1=易混淆难点
    FOREIGN KEY (chapter_id) REFERENCES chapters(id)
);

-- 关系边表（有向图）
CREATE TABLE relations (
    id               INTEGER PRIMARY KEY AUTOINCREMENT,
    from_concept_id  INTEGER NOT NULL,
    to_concept_id    INTEGER NOT NULL,
    relation_type    TEXT NOT NULL,          -- 见下方关系类型说明
    FOREIGN KEY (from_concept_id) REFERENCES concepts(id),
    FOREIGN KEY (to_concept_id)   REFERENCES concepts(id)
);
```

**关系类型（`relation_type` 枚举）：**

| 类型 | 语义 | 出题用途 |
|------|------|---------|
| `is_a` | A 是 B 的一种（上下位） | 分类型单选、填空 |
| `contrasts_with` | A 与 B 形成对比 | 多选题、简答比较题 |
| `depends_on` | A 成立依赖 B 为前提 | 逻辑推断型是非题 |
| `leads_to` | A 导致/推动 B（因果） | 论述题、材料分析题 |

**为什么用 SQLite 而不是图数据库（Neo4j）？**

本项目图规模小（全书概念总量约 200-400 个节点，关系约 300-600 条），SQLite 的关系查询完全够用，且零部署成本。若未来需要复杂图算法（PageRank、社区发现），可以将 SQLite 数据导出后用 NetworkX 处理，不需要上 Neo4j。

---

## 5. 模块详解

### 5.1 文档解析 `parser.py`

**核心问题：OCR 文本的结构不规范**

教材经 PaddleOCR 转换后存在若干噪音，解析器需要应对：

| 问题 | 示例 | 处理方式 |
|------|------|---------|
| 章节标题 `#` 层级不一致 | 第十五章用 `#` 而非 `##` | 正则匹配 `#{1,2}` |
| 全角空格 | `## 第四章　农业产业化` | `\s*` 匹配任意空白 |
| 学习目标前有 OCR 噪字 | `## 国【学习目标】` | 匹配 `[^\n【]*【学习目标】` |
| 章节文本过长 | 第十二章 45,945 字 | 智能首尾截断，中间省略 |

**章节识别正则：**

```python
_CHAPTER_RE = re.compile(
    r'^#{1,2} (第[一二三四五六七八九十百]+章)\s*(.+)$',
    re.MULTILINE,
)
_INTRO_RE = re.compile(r'^## 导论\s*$', re.MULTILINE)
_GOAL_RE  = re.compile(
    r'^## [^\n【]*【学习目标】[^\n]*\n(.*?)(?=\n## |\n# |\Z)',
    re.MULTILINE | re.DOTALL,
)
```

**截断策略：**

超过 30,000 字（约 15K token）的章节采用"保留首尾"策略：

```python
def _truncate(content, max_chars):
    half = max_chars // 2
    return content[:half] + "\n\n[...中间部分已省略...]\n\n" + content[-half:]
```

选择保留首尾而非只保留开头，是因为教材通常**前半**是概念定义，**后半**是案例和总结，两者对出题都有价值。

**解析结果（本教材）：**

| 序号 | 章节 | 原始字数 | 截断 |
|------|------|---------|------|
| 0 | 导论 | 17,261 | 否 |
| 1-6 | 第一至六章 | 12,370~29,097 | 否 |
| 7 | 第七章（农业科技） | 33,541 | 是 |
| 8-11 | 第八至十一章 | 17,225~29,904 | 否 |
| 12 | 第十二章（农产品市场） | 45,945 | 是 |
| 13 | 第十三章 | 21,790 | 否 |
| 14 | 第十四章（农业现代化） | 40,683 | 是 |
| 15-16 | 第十五、十六章 | 19,279~19,374 | 否 |

---

### 5.2 数据库层 `db.py`

提供四个核心函数：

```python
init_db()                          # 建表（幂等）
save_chapter(id, number, name, content, goals)  # upsert 章节
save_kg(chapter_id, kg_data)       # 覆盖写入一章的概念和关系
get_chapter_kg(chapter_id) -> dict # 读取一章的 KG
get_all_chapters() -> list         # 列出所有已入库章节
```

**`save_kg` 的写入逻辑：**

采用"先删后写"策略以避免主键冲突：

```
1. 查询该章节下所有 concept.id
2. 用这些 id 删除对应的 relations 行（级联）
3. 删除该章节下所有 concepts 行
4. 重新插入 concepts，建立 name→id 映射
5. 插入 relations（使用 name→id 映射转换外键）
```

`key_points` / `difficulty_points` 字段中的概念若未出现在 `concepts` 列表，会自动补充插入（避免出题时找不到对应节点）。

---

### 5.3 知识图谱提取 `kg_extractor.py`

**API 调用参数：**

```python
client.chat.completions.create(
    model="deepseek-chat",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.3,   # 低温度保证 JSON 格式稳定性
    max_tokens=2000,   # KG 输出不需要很长
)
```

温度设为 0.3 而非 0：完全贪心解码（temperature=0）在 JSON 输出时有时会陷入重复循环；0.3 在保持格式稳定的同时允许一定多样性。

**JSON 容错处理：**

LLM 偶尔会在 JSON 外包裹 markdown 代码块（`` ```json ... ``` ``），`_parse_json` 函数会先剥离这层包装再解析：

```python
def _parse_json(raw: str) -> dict:
    text = raw.strip()
    if text.startswith("```"):
        text = "\n".join(text.splitlines()[1:])
    if text.endswith("```"):
        text = "\n".join(text.splitlines()[:-1])
    return json.loads(text.strip())
```

JSON 解析失败时，自动追加指令（`temperature=0.1`）重试一次，若仍失败则抛出异常跳过该章节。

**重试策略（指数退避）：**

```python
for attempt in range(3):
    try:
        return api_call()
    except Exception:
        time.sleep(2 ** attempt)  # 1s → 2s → 4s
        if attempt == 2: raise
```

---

### 5.4 Prompt 工程 `prompts.py`

系统使用两个 Prompt，分别对应两阶段调用。

#### KG 提取 Prompt 设计要点

```
你是农业经济学专家。请分析以下章节，输出 JSON 格式知识图谱。
...
relation_type 只能是 4 种之一：is_a / contrasts_with / depends_on / leads_to
relations 中出现的概念名称必须在 concepts 列表中存在
仅输出 JSON，不要有 ```json 等标记
```

关键约束：**强制 relation_type 枚举** 和 **概念名称一致性**。

不约束概念数量（10-20 个），是因为不同章节内容密度差异很大（导论和短章节概念少，农产品市场章节概念多）。

#### 题目生成 Prompt 结构

```
[系统角色定义]
[KG 摘要注入]
  → 重点知识点（must cover）
  → 难点知识点（prioritize）
  → 对比关系对（→ 多选/简答）
  → 因果关系对（→ 论述题）
[章节全文]
[出题要求]
  → 题型数量
  → 难度分布 3:5:2
  → 格式规范（与现有系统导入格式完全对齐）
[格式示例]
```

**Prompt 长度（典型章节）：**

| 部分 | 约占字符数 |
|------|---------|
| KG 摘要注入 | ~500 |
| 章节文本 | ~15,000 |
| 出题要求 + 格式示例 | ~3,000 |
| **合计（输入）** | **~18,500 字符 ≈ 9,250 token** |
| 输出（25 题） | **~4,000 token** |

---

### 5.5 题目生成 `question_generator.py`

**API 调用参数：**

```python
client.chat.completions.create(
    model="deepseek-chat",
    temperature=0.7,   # 高于 KG 提取，允许题目表述多样化
    max_tokens=6000,   # 25题约需 4000 token，留余量
)
```

**格式校验（轻量）：**

生成后用正则统计各题型数量，数量异常时打印警告但不强制重试（避免 API 费用翻倍）：

```python
def _count_questions(text):
    return {
        "单选": len(re.findall(r"^\[单选\]", text, re.MULTILINE)),
        "多选": len(re.findall(r"^\[多选\]", text, re.MULTILINE)),
        ...
    }
```

**输出文件格式：**

```
chapter_01_第一章_农业经营制度.txt
```

文件开头有两行注释，导入时会被系统识别为普通文本忽略（系统只解析 `[题型]` 标记行）：

```
# 第一章 农业经营制度
# 知识图谱驱动出题 | 可直接导入题库系统
```

---

### 5.6 断点续传机制

`progress.json` 格式：

```json
{
  "kg_extracted": [0, 1, 2, 3],
  "questions_generated": [0, 1, 2]
}
```

两个列表分别记录**已完成 KG 提取**和**已完成出题**的章节 ID（整数）。

**续传逻辑：**

```python
done_ids = set(progress.get("kg_extracted", []))
pending = [ch for ch in chapters if ch["id"] not in done_ids]
```

每处理完一章就立即写入 `progress.json`（不等全部完成），确保单章失败不影响已完成章节的进度。

**进度独立性：** KG 提取和题目生成的进度互相独立。可以先提取所有章节的 KG，再批量生成题目；也可以逐章交替进行。

**重置进度（菜单 [7]）：** 只清空 `progress.json`，不删除 `kg.db` 和 `output/` 里的文件，允许用户重新生成部分章节而不丢失其他章节的成果。

---

### 5.7 交互菜单 `main.py`

菜单采用**同步阻塞**模式（无异步），每次选择后立即执行，执行完才返回主菜单。对于批量处理任务，用户可以在任意章节完成后按 `Ctrl+C` 中断，进度已保存。

**章节懒加载：** `_chapters` 变量在首次需要时才解析 MD 文档（菜单选 [1] 或任何需要章节列表的操作），避免每次启动都等待解析。

---

### 5.8 API Key 配置 `_setup_key.py`

基于 `tkinter` 构建的 GUI 对话框，三种运行场景：

| 场景 | 行为 |
|------|------|
| `.env` 中无有效 Key | 直接弹出输入框 |
| `.env` 中有有效 Key | 弹出确认框（"是否重新输入？"） |
| 用户点取消 | 退出码 1，bat 脚本检测到后终止启动 |

输入框支持「显示/隐藏」切换，默认遮蔽（`show="*"`）防止被他人看到。

---

## 6. 知识图谱的作用与局限

### 真正有价值的地方

**① 强制覆盖，对抗注意力偏好**

LLM 读取长文本时倾向于从最显眼的段落出题（通常是引言、案例、结论），而跳过枯燥的定义段落。KG 把必考知识点显式列出并注入 prompt，相当于给出题加了"必须覆盖"的约束。

**② 关系类型直接映射题型**

这是 KG 最具实质价值的用途：

```
contrasts_with  ──▶  "比较 A 和 B 的异同"（简答/多选）
leads_to        ──▶  "论述 A 导致 B 的内在机制"（论述）
depends_on      ──▶  "判断：没有 A 就不可能有 B"（是非）
is_a            ──▶  "下列哪项属于 B 的类型"（单选）
```

没有显式关系提取，LLM 生成的主观题方向是随机的；有了关系图谱，论述题和比较题会精准落在教材真正有逻辑联系的概念对上。

**③ 难点标记控制难度分布**

`is_difficult_point: true` 的概念被明确要求出 medium/hard 题，比让 LLM 自己判断"哪些概念难"更可靠——LLM 对"学生视角的难度"感知较弱。

**④ KG 是可持久化的资产**

`kg.db` 独立于题目生成存在。可以：
- 修改难点标记后重新生成某章题目
- 跨章节查询相关概念（为跨章综合题提供线索）
- 导出为可视化图（未来功能）

### 诚实的局限性

**这不是真正的 RAG**

标准 RAG（Retrieval-Augmented Generation）流程是：
```
问题/任务 → 向量检索相关段落 → 将检索结果注入 prompt → LLM 生成
```

本系统没有向量检索步骤，全章节文本直接入 prompt。本质上是：
```
章节文本（全文）+ KG 结构化提示 → LLM 生成
```

"RAG" 的价值在本系统中体现为**结构化的上下文增强**，而非检索。这在每章 ≤15K token 的情况下是合理的——没必要分块检索。

**KG 质量的天花板等于第一次 API 调用的质量**

如果 DeepSeek 在 KG 提取阶段漏掉了某个重要概念，第二阶段的出题也会系统性地忽略它。两阶段调用是同一个 LLM，上限相同。

**关系类型是人为枚举的**

实际教材中的概念关系比四种类型复杂得多（包含、举例、数量关系、历史演变……），强制映射到四种关系类型会有信息损失。

---

## 7. Token 用量与成本估算

以 DeepSeek-V3 定价（输入 ¥1/百万 token，输出 ¥2/百万 token）估算全书：

| 阶段 | 每章输入 | 每章输出 | 全书（17章）输入 | 全书输出 |
|------|---------|---------|--------------|--------|
| KG 提取 | ~5,000 token | ~1,000 token | ~85,000 | ~17,000 |
| 题目生成 | ~9,500 token | ~4,000 token | ~161,500 | ~68,000 |
| **合计** | | | **~246,500** | **~85,000** |

```
总费用 ≈ (246,500 × ¥1 + 85,000 × ¥2) / 1,000,000
       ≈ (¥0.25 + ¥0.17)
       ≈ ¥0.42
```

**实际费用受以下因素影响：**
- 章节文本长度（截断章节费用更低）
- JSON 解析失败的重试次数
- 题目格式不合格时的人工重新生成

---

## 8. 配置参数说明

所有可调参数集中在 `config.py`：

```python
# 模型配置
DEEPSEEK_MODEL = "deepseek-chat"        # 可换为 deepseek-reasoner 等

# 题量配置（精简版，约25题/章）
QUESTION_CONFIG = {
    "单选": 10,
    "多选": 3,
    "是非": 5,
    "简答": 3,
    "简答>论述": 2,
    "简答>材料分析": 2,
}

# 章节文本截断阈值（字符数）
# 30000字 ≈ 15000 token，在 DeepSeek 64K 上下文中留有充足余量
MAX_CHAPTER_CHARS = 30000
```

**调整题量：** 直接修改 `QUESTION_CONFIG` 字典，各值之和不超过 40 为宜（单次 max_tokens=6000 约够 35-40 题）。

**切换模型：** 将 `DEEPSEEK_MODEL` 改为 `"deepseek-reasoner"` 可使用推理模型（更慢、更贵，但对复杂论述题质量更高）。

---

## 9. 通用化前端版本设计方案

> 以下是从当前"单一课程离线脚本"升级为"多课程通用 Web 系统"的详细设计方案。

### 9.1 目标与约束

**目标：**
- 支持任意课程文档上传（PDF / DOCX / PPT / TXT / MD）
- 浏览器内完成知识图谱查看、题量配置、题目审核
- 多课程并行管理，互不干扰
- 出题过程可视（实时进度）

**约束：**
- 与现有 Flask 题库系统共用代码库（尽量复用）
- 不引入重型基础设施（不强制要求 Redis、Celery）

---

### 9.2 架构选型对比

#### 方案 A：集成进现有 Flask 系统（推荐）

在现有系统中新增一个 `ai_gen` Blueprint，复用现有的数据库（`exam_system.db`）和题目导入逻辑。

```
优点：
  - 统一入口，生成的题目直接写入题库，无需手动导入
  - 复用现有用户界面风格
  - 维护成本低
缺点：
  - `server.py` 变重，需要良好的模块拆分
  - 长时间 API 调用（出题过程）需要异步处理，否则阻塞 Flask 主线程
```

#### 方案 B：独立 Web 应用

独立的 FastAPI 或 Flask 应用，通过 REST API 与现有系统交换数据（推送题目到导入接口）。

```
优点：
  - 完全解耦，迭代互不影响
  - 可以独立部署、独立扩展
缺点：
  - 两套前端、两个服务进程
  - 数据同步需要额外设计
```

**本文档采用方案 A 详细展开。**

---

### 9.3 新增数据库表（扩展 exam_system.db）

```sql
-- 文档表：管理上传的教材文档
CREATE TABLE documents (
    id           INTEGER PRIMARY KEY AUTOINCREMENT,
    name         TEXT NOT NULL,          -- 显示名称，如「农业经济学（第3版）」
    filename     TEXT NOT NULL,          -- 上传文件名
    file_path    TEXT NOT NULL,          -- 服务器存储路径
    file_type    TEXT NOT NULL,          -- md / pdf / docx / pptx / txt
    status       TEXT DEFAULT 'pending', -- pending→parsed→kg_ready→done
    chapter_count INTEGER DEFAULT 0,
    created_at   TEXT DEFAULT (datetime('now'))
);

-- 文档章节表（替代离线版的 chapters 表）
CREATE TABLE doc_chapters (
    id           INTEGER PRIMARY KEY AUTOINCREMENT,
    document_id  INTEGER NOT NULL,
    number       TEXT NOT NULL,           -- '第一章'
    name         TEXT NOT NULL,
    content      TEXT NOT NULL,
    learning_goals TEXT DEFAULT '',
    char_count   INTEGER DEFAULT 0,
    FOREIGN KEY (document_id) REFERENCES documents(id)
);

-- AI 出题任务表
CREATE TABLE gen_tasks (
    id           INTEGER PRIMARY KEY AUTOINCREMENT,
    document_id  INTEGER NOT NULL,
    chapter_id   INTEGER,                -- NULL 表示全书任务
    task_type    TEXT NOT NULL,          -- 'kg_extract' / 'gen_questions'
    status       TEXT DEFAULT 'pending', -- pending/running/done/failed
    progress     INTEGER DEFAULT 0,      -- 0-100
    result_file  TEXT,                   -- 生成的题目文件路径
    error_msg    TEXT,
    created_at   TEXT DEFAULT (datetime('now')),
    updated_at   TEXT DEFAULT (datetime('now')),
    FOREIGN KEY (document_id) REFERENCES documents(id)
);

-- 知识图谱表（对应离线版的 concepts + relations）
-- 表结构与 kg.db 相同，增加 document_id 外键
CREATE TABLE kg_concepts (
    id                 INTEGER PRIMARY KEY AUTOINCREMENT,
    document_id        INTEGER NOT NULL,
    chapter_id         INTEGER NOT NULL,
    name               TEXT NOT NULL,
    description        TEXT DEFAULT '',
    is_key_point       INTEGER DEFAULT 0,
    is_difficult_point INTEGER DEFAULT 0
);

CREATE TABLE kg_relations (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    from_concept_id INTEGER NOT NULL,
    to_concept_id   INTEGER NOT NULL,
    relation_type   TEXT NOT NULL
);
```

---

### 9.4 文档摄入层（多格式支持）

离线版只支持 Markdown，通用版需要统一的摄入 Pipeline：

```python
# app/ingestion.py

class DocumentIngester:
    """将各种格式文档统一转换为章节列表。"""

    def ingest(self, file_path: str, file_type: str) -> list[ChapterDict]:
        converter = self._get_converter(file_type)
        raw_text = converter.to_markdown(file_path)
        return parse_chapters(raw_text)

    def _get_converter(self, file_type):
        return {
            "md":   MarkdownPassthrough(),
            "txt":  TxtConverter(),
            "pdf":  PDFConverter(),    # pdfminer.six 或 PyMuPDF
            "docx": DocxConverter(),   # python-docx
            "pptx": PptxConverter(),   # python-pptx（按幻灯片切章节）
        }[file_type]
```

**各格式处理重点：**

| 格式 | 挑战 | 推荐库 |
|------|------|-------|
| PDF（文本型） | 页眉页脚干扰、分栏 | `pdfminer.six` 或 `PyMuPDF` |
| PDF（扫描版） | 需要 OCR | `paddleocr` 或 `pytesseract` |
| DOCX | 标题样式提取（H1/H2→章节） | `python-docx` |
| PPTX | 每张幻灯片视为一个"节" | `python-pptx` |
| TXT | 用空行/缩进推断章节 | 自定义规则 |

**章节识别通用策略：**

无法依赖特定 Markdown 标题格式时，可用 LLM 辅助划分章节：

```python
# 备用方案：让 LLM 标注章节边界
prompt = """以下是教材文本，请识别章节标题，
输出格式：{"chapters": [{"title":"...", "start_line":N}]}
"""
```

---

### 9.5 后台任务处理（异步架构）

KG 提取和出题每章需 5-30 秒，不能在 HTTP 请求内同步等待。

#### 轻量方案：Python threading（无额外依赖）

```python
# app/ai_gen/tasks.py
import threading
from .pipeline import run_pipeline

_running_tasks: dict[int, threading.Thread] = {}

def start_task(task_id: int, **kwargs):
    t = threading.Thread(
        target=_worker, args=(task_id,), kwargs=kwargs, daemon=True
    )
    _running_tasks[task_id] = t
    t.start()

def _worker(task_id, **kwargs):
    try:
        update_task_status(task_id, "running")
        run_pipeline(**kwargs, progress_callback=lambda p: update_progress(task_id, p))
        update_task_status(task_id, "done")
    except Exception as e:
        update_task_status(task_id, "failed", error=str(e))
```

适合：单用户或低并发场景（≤3 个并行任务）。

#### 生产方案：Celery + Redis

```python
# tasks.py
from celery import Celery
app = Celery('ai_gen', broker='redis://localhost:6379/0')

@app.task(bind=True)
def extract_kg_task(self, document_id, chapter_id):
    # self.update_state 更新进度
    ...
```

适合：多用户、需要任务优先级、需要失败重试队列。

---

### 9.6 前端页面设计

新增「AI 出题」Tab（第 7 个 Tab），包含三个子页面：

#### 子页面 1：文档管理

```
┌─────────────────────────────────────────────┐
│  AI 出题  /  文档管理                        │
├─────────────────────────────────────────────┤
│  [+ 上传文档]                                │
│                                             │
│  农业经济学（第3版）  17章  已就绪  [出题] [删除] │
│  管理研究方法         12章  解析中...         │
│  林业经济学           待上传                  │
└─────────────────────────────────────────────┘
```

#### 子页面 2：知识图谱查看 + 出题配置

```
┌──────────────────────┬──────────────────────┐
│  知识图谱             │  出题配置             │
│                      │                      │
│  章节选择：[第一章▾]  │  API: [DeepSeek  ▾]  │
│                      │  单选: [10] 多选: [3]  │
│  [可视化图谱区域]     │  是非: [5]  简答: [3]  │
│  ·家庭承包经营[重点]  │  论述: [2]  材料: [2]  │
│  ──is_a──▶           │                      │
│  ·双层经营体制[难点]  │  难度: easy 30%       │
│  ──leads_to──▶       │       medium 50%      │
│  ·农村家庭承包改革    │       hard 20%        │
│                      │                      │
│  [编辑概念] [编辑关系]│  [开始生成]           │
└──────────────────────┴──────────────────────┘
```

**KG 可视化推荐库：**

| 库 | 优点 | 缺点 |
|----|------|------|
| `vis.js Network` | 交互丰富，力导向布局 | 较重（~400KB） |
| `Cytoscape.js` | 样式高度可定制 | API 复杂 |
| `D3.js` | 完全定制 | 开发成本高 |
| `ECharts Graph` | 中文文档好，已在国内广泛使用 | 与现有技术栈更匹配 |

**推荐：ECharts**，因为项目已面向中文用户，且 ECharts 的 Graph 组件对几百个节点的规模性能很好。

#### 子页面 3：题目审核

```
┌─────────────────────────────────────────────┐
│  出题进度：第一章 ✓  第二章 ✓  第三章 生成中...│
│  ████████████░░░░░░░░  60%  预计剩余 2分钟    │
├─────────────────────────────────────────────┤
│  第一章 农业经营制度  [查看] [重新生成] [导入] │
│  ─────────────────────────────────────────  │
│  [单选][B]  以下哪项是我国农业基本经营制度？   │
│  [A] ... [B] 家庭承包经营 [C] ... [D] ...    │
│  ✓ 格式正确  知识点:第一章  难度:easy         │
│  [编辑] [删除]                               │
└─────────────────────────────────────────────┘
```

#### 实时进度推送（SSE）

```python
# app/ai_gen/routes.py
from flask import Response, stream_with_context

@bp.route('/tasks/<int:task_id>/stream')
def task_stream(task_id):
    def generate():
        while True:
            task = get_task(task_id)
            yield f"data: {json.dumps({'status': task.status, 'progress': task.progress})}\n\n"
            if task.status in ('done', 'failed'):
                break
            time.sleep(1)
    return Response(stream_with_context(generate()), mimetype='text/event-stream')
```

前端使用 `EventSource` 监听：

```javascript
const es = new EventSource(`/api/ai_gen/tasks/${taskId}/stream`);
es.onmessage = (e) => {
    const data = JSON.parse(e.data);
    updateProgressBar(data.progress);
    if (data.status === 'done') es.close();
};
```

---

### 9.7 题目质量控制工作流

当前离线版生成后直接导入，通用版应增加审核层：

```
生成完成
    │
    ▼
[自动校验]──格式错误──▶ 标记为 warning，显示具体错误位置
    │
  格式正确
    │
    ▼
[人工审核]  浏览器内预览每道题
    │        可单题编辑/删除/重新生成
    │
    ▼
[确认导入]──▶ 调用现有 POST /api/questions 接口批量写入题库
```

**单题重新生成：** 传入题目所在知识点和题型，向 LLM 请求仅重新生成该题：

```python
prompt = f"""
请重新生成1道 [单选] 题，知识点为「{concept_name}」，难度 medium。
...（完整格式要求）
"""
```

---

### 9.8 多 API Provider 支持

通用版应允许用户在 UI 里切换 LLM 提供商：

```python
# app/ai_gen/llm_client.py

class LLMClient:
    def __init__(self, provider: str, api_key: str):
        if provider == "deepseek":
            self.client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
            self.model = "deepseek-chat"
        elif provider == "qwen":
            self.client = OpenAI(api_key=api_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
            self.model = "qwen-plus"
        elif provider == "openai":
            self.client = OpenAI(api_key=api_key)
            self.model = "gpt-4o-mini"
        # 所有 provider 统一用 OpenAI-compatible 接口
```

阿里云 DashScope 和 DeepSeek 都提供 OpenAI 兼容接口，只需切换 `base_url` 和 `model` 即可，无需改变调用代码。

---

### 9.9 从当前版本迁移的路线图

| 阶段 | 工作内容 | 周期估算 |
|------|---------|---------|
| **Phase 1**：后端 API 化 | `rag_pipeline/` 各模块加 `document_id` 参数，封装为 Flask Blueprint | 3-5天 |
| **Phase 2**：文档摄入 | 实现 PDF/DOCX 转换器，统一摄入接口 | 3-5天 |
| **Phase 3**：异步任务 | 用 `threading` 实现后台任务，加 `gen_tasks` 表 | 2-3天 |
| **Phase 4**：前端基础 | 文档管理页 + 出题配置页 + SSE 进度显示 | 5-7天 |
| **Phase 5**：KG 可视化 | ECharts Graph 渲染，支持概念编辑 | 3-5天 |
| **Phase 6**：题目审核 | 预览、单题编辑/重生成、批量导入 | 3-5天 |
| **合计** | | **约 3-4周** |

**优先级建议：** Phase 1-3 完成后，系统就能以"后台任务 + 最终导入"模式稳定运行，Phase 4-6 是体验优化，可以按需迭代。

---

*文档完 | rag_pipeline v1.0*
